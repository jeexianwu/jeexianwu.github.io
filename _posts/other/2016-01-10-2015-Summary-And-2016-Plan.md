---
layout: default
title: 2015-Summary-2016-Plan
comments: true
categories: [other]
---

# **2015 Summary And 2016 Plan**

标签（空格分隔）： 总结 计划

---
时光匆匆溜过，感觉去年就在眼前，回顾一年工作学习上的增进与不足也是十分有益的事情。

# 2015 Summary


----------


## 工作篇之“做了什么”

这一年可谓“折腾”，从自然序言处理、文本挖掘、计算广告、实时竞价、并发编程到统计平台、大数据生态圈，再到分布式消息系统、网络编程最后到数据仓库、OLAP、数据服务系统开发，一年下来都玩了个遍，虽说有点杂，但对自己来说收获还是不小的，不是有那句话嘛“人生就是不停的折腾”-_-。

### 1.DSP及周边
从入职到今年的前两个季度都在围绕该系统开展工作，期间我参与了数据和算法的开发以及部分系统的开发与集成，主要有以下几块：

 - DMP系统(暂且这么称呼)
使用文本挖掘的分布式分类算法对文本进行自动分类，对用户的历史交互数据进行分类以给每个用户打上标签进而获得用户的喜好，这部分可以算作是DMP系统的雏形，待解决的主要问题是数据源和CookieMapping。期间会涉及到分词、特征词提取、分类算法选择以及分布式处理以及标签体系的制定等问题，经过实验，这些目前都有比较好的解决方法。
 
 - 用户及广告搜索引擎
 主要是用户标签喜好以及广告相关信息的索引与检索，并按着相应的逻辑进行排序，并将部分结果输入到实时竞价模块以获得对特定用户进行候选广告曝光的出价。

 - 实时竞价
 比较难处理的问题就是CTR预估和出价的动态调整，这个在目前的版本中都已经实现，只是效果还要更真实点的数据进行测试改进。

 - DSP系统基础模块集成与程序化购买周边配套的了解和学习

### 2.数据统计平台
是一套基于HUE的大数据统计分析平台，几乎囊括了大数据生态圈中大部分的主流组件，使得数据预处理、数据异构存储、离线任务调度、数据统计、监控报警等任务可以无缝衔接，减少开发周期的同时提供了可靠的服务。但最终没使用该平台的主要原因是异构数据存储中数据更新的一致性问题需要系统设计、从底层上解决，特别是面对大数据量自由查询的需求与数据记录更新的需求需要同时满足时，这套系统已不再有优势了。这一块主要是熟悉大数据各组件的工作原理使用方式并集成到系统中，也算是开阔眼界把。

### 3.Danuby相关

 - 海蜜日志消费端的开发：重点在ORC格式存储与基础事件的更新与生成以及可扩展性
 
 - danuby通用客户端的开发：满足常见的开发需求，着重在异步、加密、高效、透明易用性上进行了开发与优化。

### 4.海蜜数据分析服务

 - 查询引擎的选型与优化
 - 元数据的定义与更新(与服务端)
 - 各统计模型接口的开发(包括查询规则和sql模版的设计)


----------


## 工作篇之“学到了什么”&收获

 - 有关计算广告学方面的知识和实践、文本挖掘也有了较为深入的研究
 - 大数据生态圈以及大数据技术有了更深层次的理解与使用心得
 - Java技术栈的深入，特别是并发编程和网路编程以及struct框架的web开发
 - 沟通交流、学习、团队协作的重要性


----------


## 工作篇之“不足”&补短

 - 对某些问题的细节把握的不是很到位，这说明思考的不够深入以及缺少类似的经验:
 >通过对问题的深挖和广泛的学习与提问争取得到有效提升

 - 缺少大型线上系统的开发经验，特别是类似DSP这种高并发、低延迟、高可用系统的实际开发经验不足:
 >通过学习相关技能、研究优秀项目并积极参与到该类系统的实际开发中来弥补

 - 前端开发，有时会遇到前端的问题，可是对前端还基本停留在html以及简单css阶段:
>已经列入学习计划中，以期得到较大提升


----------


## 工作周边发展情况

 - 机器学习&深度学习：今年断断续续地看了一些论文和代码，没能很及时的总结与实践；总体上该领域的发展比较快，知识体系需要跟着更新，特别是深度学习或许会是最近几年的发展趋势；
 - spark：通过项目中的实战已经达到熟练使用的程度，但是需要在框架、原理和调优方面继续深入；
 - scala/go：这两个语言都只看了皮毛，主要是没有看清二者以后的发展方向或者说趋势变化太快没能下决心去深入，后续在使用spark的基础上会适当深入scala；
 - 爬虫：今年也很多地方用到了爬虫，通过实践以及vic的工作交接更加熟悉爬虫系统以及优化方向；
 - python栈：“人生苦短我用python”还真有点这样的小感慨，今年我也在各项目中穿插使用了python，对python栈又有了进一步的深入；


----------


# 2016 Plan

 - 深入研究spark，特别是mllib与graphx，并更多地应用到实际业务中来；
 - 重读机器学习相关理论与论文，所谓温故而知新，而且当下流行的算法都源于这些经典的理论；
 - 深度学习方面主要关注两个开源库：Theano和Tensorflow,采用先体验在理论然后再实战的方式进行学习；
 - python栈：深入python开发栈，争取可以做到专职python工程师的水准；
 - 容器技术：docker无疑已经取得了容器之争的胜利，“上云”已经成为发展趋势，微服务也深入到各大小公司架构中，需要去了解学习下；
 - 数据可视化：准备从这个领域出发深入大数据；
 - 前端开发作为兴趣，也列入到个人学习计划中；
 - 如果可以尽量多的去学习下金融以及金融风险控制方面的知识；
 - 多读书


----------


# 对自己和团队的建议

 - 加强协作与沟通，建立常规有效的沟通机制(特别是2016年团队大了以后)
 - 营造严谨、求真、务实、上进的积极氛围
 - 个人和团队尽可能地发挥积极的影响力
 - 丰富团建，让大家有归属感、集体感，更能激发团队的整体战斗力